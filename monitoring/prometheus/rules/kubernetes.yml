apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kubernetes
spec:
  groups:
    - name: k8s.rules.container_cpu_usage_seconds_total
      rules:
        - record: node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate
          expr: |-
            sum by (cluster, namespace, pod, container) (
              irate(container_cpu_usage_seconds_total{pod!=""}[5m])
            ) * on (cluster, namespace, pod) group_left(node) topk by (cluster, namespace, pod) (
              1, max by (cluster, namespace, pod, node) (kube_pod_info{node!=""})
            )
    - name: kubernetes
      rules:
        - alert: KubernetesNodeNotReady
          expr: kube_node_status_condition{condition="Ready", status="true"} == 0
          for: 5m
          keep_firing_for: 2m
          labels:
            severity: critical
          annotations:
            summary: Kubernetes Node not ready (instance {{ $labels.instance }})
            description: "Node {{ $labels.node }} has been unready for while"
        # Kubernetes Node with disabled schedules are fine.
        # This alarm can be useful to get warned if there are nodes which are longer unscheduled.
        - alert: KubernetesNodeSchedulingDisabled
          expr: kube_node_spec_taint{key="node.kubernetes.io/unschedulable"} == 1
          for: 30m
          labels:
            severity: warning
          annotations:
            summary: Kubernetes Node scheduling disabled (instance {{ $labels.instance }})
            description: "Node {{ $labels.node }} has been marked as unschedulable for more than 30 minutes."
        - alert: KubernetesNodeMemoryPressure
          expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
          for: 2m
          keep_firing_for: 2m
          labels:
            severity: critical
          annotations:
            summary: Kubernetes Node memory pressure (instance {{ $labels.instance }})
            description: "Node {{ $labels.node }} has MemoryPressure condition"
        - alert: KubernetesNodeDiskPressure
          expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
          for: 2m
          keep_firing_for: 2m
          labels:
            severity: critical
          annotations:
            summary: Kubernetes Node disk pressure (instance {{ $labels.instance }})
            description: "Node {{ $labels.node }} has DiskPressure condition"
        - alert: KubernetesNodeNetworkUnavailable
          expr: kube_node_status_condition{condition="NetworkUnavailable",status="true"} == 1
          for: 2m
          keep_firing_for: 2m
          labels:
            severity: critical
          annotations:
            summary: Kubernetes Node network unavailable (instance {{ $labels.instance }})
            description: "Node {{ $labels.node }} has NetworkUnavailable condition"
        - alert: KubernetesNodeOutOfPodCapacity
          expr: sum by (node) ((kube_pod_status_phase{phase="Running"} == 1) + on(uid, instance) group_left(node) (0 * kube_pod_info{pod_template_hash=""})) / sum by (node) (kube_node_status_allocatable{resource="pods"}) * 100 > 90
          for: 2m
          keep_firing_for: 2m
          labels:
            severity: warning
          annotations:
            summary: Kubernetes Node out of pod capacity (instance {{ $labels.instance }})
            description: "Node {{ $labels.node }} is out of pod capacity\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        - alert: KubernetesContainerOomKiller
          expr: (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}[10m]) == 1
          for: 0m
          keep_firing_for: 2m
          labels:
            severity: warning
          annotations:
            summary: Kubernetes Container oom killer (instance {{ $labels.instance }})
            description: "Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes."
        - alert: KubernetesJobFailed
          expr: kube_job_status_failed > 0
          for: 0m
          keep_firing_for: 2m
          labels:
            severity: warning
          annotations:
            summary: Kubernetes Job failed (instance {{ $labels.instance }})
            description: "Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete"
        - alert: KubernetesJobNotStarting
          expr: kube_job_status_active == 0 and kube_job_status_failed == 0 and kube_job_status_succeeded == 0 and (time() - kube_job_status_start_time) > 600
          for: 0m
          keep_firing_for: 2m
          labels:
            severity: warning
          annotations:
            summary: Kubernetes Job not starting (instance {{ $labels.instance }})
            description: "Job {{ $labels.namespace }}/{{ $labels.job_name }} did not start for 10 minutes\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        - alert: KubernetesPodNotHealthy
          expr: sum by (namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown|Failed"} * on(namespace, pod) group_left() (count by (namespace, pod) (kube_pod_owner{owner_kind!="Job"}))) > 0
          for: 10m
          keep_firing_for: 5m
          labels:
            severity: error
          annotations:
            summary: Kubernetes Pod not healthy (instance {{ $labels.instance }})
            description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-running state for longer than 10 minutes."
        - alert: KubernetesPodCrashLooping
          expr: increase(kube_pod_container_status_restarts_total[1m]) > 3
          for: 2m
          keep_firing_for: 5m
          labels:
            severity: error
          annotations:
            summary: Kubernetes pod crash looping (instance {{ $labels.instance }})
            description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        - alert: KubernetesDeploymentGenerationMismatch
          expr: kube_deployment_status_observed_generation != kube_deployment_metadata_generation
          for: 10m
          keep_firing_for: 5m
          labels:
            severity: critical
          annotations:
            summary: Kubernetes Deployment generation mismatch (instance {{ $labels.instance }})
            description: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has failed but has not been rolled back.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        - alert: KubernetesDaemonsetRolloutStuck
          expr: kube_daemonset_status_number_ready / kube_daemonset_status_desired_number_scheduled * 100 < 100 or kube_daemonset_status_desired_number_scheduled - kube_daemonset_status_current_number_scheduled > 0
          for: 10m
          keep_firing_for: 5m
          labels:
            severity: warning
          annotations:
            summary: Kubernetes DaemonSet rollout stuck (instance {{ $labels.instance }})
            description: "Some Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are not scheduled or not ready\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        - alert: KubernetesApiServerErrors
          expr: sum(rate(apiserver_request_total{job="apiserver",code=~"(?:5..)"}[1m])) by (instance, job) / sum(rate(apiserver_request_total{job="apiserver"}[1m])) by (instance, job) * 100 > 3
          for: 2m
          keep_firing_for: 5m
          labels:
            severity: critical
          annotations:
            summary: Kubernetes API server errors (instance {{ $labels.instance }})
            description: "Kubernetes API server is experiencing high error rate\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        - alert: KubernetesClientCertificateExpiresNextWeek
          expr: apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 7*24*60*60
          for: 0m
          keep_firing_for: 5m
          labels:
            severity: warning
          annotations:
            summary: Kubernetes client certificate expires next week (instance {{ $labels.instance }})
            description: "A client certificate used to authenticate to the apiserver is expiring next week.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
